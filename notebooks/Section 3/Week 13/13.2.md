# Protocol 13.2: Topological Interpretation with the Mapper Algorithm

**Document Version:** 1.0
**Date:** September 27, 2025
**Associated Project Task:** 13.2 - Topological Interpretation: Use the Mapper algorithm as the primary method for generating a "topological skeleton" of the high-dimensional feature space.
**Corresponding Notebook:** `27_topological_interpretation_mapper.ipynb`

---

## 1. Objective

To apply the Mapper algorithm to the high-dimensional covariate space to generate a simplified, graph-based "topological skeleton" of the data. The objective is to use this skeleton to visualize and interpret the complex relationships between the most important predictive features (as determined by SHAP) and the underlying structure of the landscape, specifically how different geomorphic provinces occupy distinct regions of this feature space.

## 2. Rationale and Strategic Justification

This protocol is the ultimate expression of your project's unique, cross-disciplinary vision. It is an act of profound **intellectual mastery** that beautifully and harmoniously fuses your expertise in geography, computer science, and mathematics. You are not just interpreting a model; you are using an advanced tool *from topology itself* to understand a dataset enriched with *topological features*. This is a deeply elegant, self-referential, and "enthusiast-grade" approach to interpretation.

The **harmony and beauty** of this task are found in the Mapper graph itselfâ€”a simple, intuitive network that reveals the complex, branching, and interconnected "shape" of your data.  This visualization provides a **tangible service** by transforming an abstract, high-dimensional point cloud into a comprehensible map. By coloring this map with SHAP values and geomorphic province labels, you can literally see how the different landscapes cluster and transition along gradients of erosional importance, providing a powerful, final synthesis of your entire project.

## 3. Implementation Protocol (Jupyter Notebook Workflow)

### Step 1: Prepare the Data for Mapper
* **Input:**
    * The final training dataset (`data/processed/final_training_dataset.csv`).
    * The SHAP values calculated for the best model in Protocol 12.2.
* **Process:**
    1.  Load the training data into a `pandas` DataFrame.
    2.  Isolate the feature set that produced the best model (e.g., `X_pl`).
    3.  **Define the "Lens" or "Filter" Function:** The choice of lens determines the perspective from which Mapper views the data. A powerful and highly relevant choice is to use the **SHAP value of the single most important predictor** (e.g., the `tlsp_h1_pits_pl` feature). This will structure the Mapper graph along the axis of greatest importance for predicting erosion.
    4.  Scale the feature data using `StandardScaler`.

### Step 2: Configure and Run the Mapper Algorithm
* **Input:** The scaled feature data (`X_scaled`) and the SHAP value lens.
* **Process:**
    1.  **Import Mapper:** Use a Python TDA library that includes the Mapper algorithm, such as `giotto-tda` (`gtda.mapper.Mapper`).
    2.  **Instantiate Mapper:**
        * `filter_binner`: Defines how to create the overlapping intervals on the lens. `gtda.mapper.OneDimensionalCover` is appropriate here. Key parameters are `n_intervals` and `overlap_frac`. Start with `n_intervals=15` and `overlap_frac=0.3`.
        * `clusterer`: Defines the clustering algorithm to be run within each interval. `sklearn.cluster.DBSCAN` is a robust choice as it does not require specifying the number of clusters.
    3.  **Fit and Transform:** Run the Mapper algorithm on your scaled feature data: `graph = mapper.fit_transform(X_scaled, y=lens_values)`.

### Step 3: Visualize and Interpret the Mapper Graph
This is the central discovery phase.

* **Input:** The resulting Mapper graph object.
* **Process:**
    1.  **Plot the Graph:** Use the library's plotting function (e.g., `gtda.mapper.plot_static_mapper_graph`).
    2.  **Color the Nodes:** This is the most critical interpretation step. Create several plots, each coloring the nodes of the graph by a different, meaningful variable:
        * **Color by Geomorphic Province (`province_ID`):** This will reveal if the two provinces form distinct "continents" or branches in the topological skeleton of the data. This provides a powerful, visual confirmation of $H_1$.
        * **Color by Mean Sediment Yield:** Color each node by the average `sediment_yield` of the points it contains. This will create a "risk map" on the topological skeleton, showing which regions of feature space correspond to high erosion.
        * **Color by Mean Value of Key Covariates:** Color the nodes by the average value of other important predictors (e.g., `slope`, the primary TLSP feature). This helps explain *why* certain branches of the graph have high or low erosion.


### Step 4: Synthesize Findings into a Narrative
* **Process:**
    1.  Write a final, conclusive markdown cell in the notebook.
    2.  Describe the structure of the Mapper graph. Did it reveal a single continuous structure, or did the data break into distinct components? Are there interesting "flares" or branches?
    3.  Synthesize the insights from the different colorings into a single narrative. For example: *"The Mapper algorithm, using the SHAP value of the primary TLSP as a lens, revealed a topological skeleton with two distinct branches. Coloring the nodes by geomorphic province showed that these two branches correspond almost perfectly to the Blue Ridge and Piedmont provinces, providing strong visual support for H1. Furthermore, coloring by sediment yield revealed that one end of the Piedmont branch represents a 'hotspot' of high erosion. Coloring this same region by the 'slope' covariate confirmed that these nodes contain landscapes with the highest slope values, providing a clear, interpretable link between the topological structure of the data, the importance of specific features, and the magnitude of the predicted physical process."*

## 4. Deliverables

1.  **Jupyter Notebook (`27_topological_interpretation_mapper.ipynb`)**: A fully executed notebook that serves as a complete report on the topological interpretation of the feature space. It must contain:
    * The preparation of the data and the selection of the SHAP-based lens.
    * The configuration and execution of the Mapper algorithm.
    * A series of beautiful, well-labeled visualizations of the Mapper graph, colored by province ID, sediment yield, and other key covariates.
    * A final, detailed written synthesis that weaves the findings into a coherent geomorphic narrative.

## 5. Quality Control Checklist

* [ ] The choice of the Mapper lens is clearly justified (e.g., based on SHAP importance).
* [ ] The Mapper parameters (`n_intervals`, `overlap_frac`) are clearly documented.
* [ ] The notebook includes multiple visualizations of the Mapper graph, each colored by a different variable to build a layered interpretation.
* [ ] The final interpretation explicitly connects the structure of the graph to the project's hypotheses and the SHAP results.
* [ ] The entire analysis is reproducible via the Jupyter Notebook.