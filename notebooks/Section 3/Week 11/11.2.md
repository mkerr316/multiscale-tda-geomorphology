# Protocol 11.2: Formal Hypothesis Testing for Landscape Characterization (H1)

**Document Version:** 1.0
**Date:** September 27, 2025
**Associated Project Task:** 11.2 - Formally test H1 using MANOVA and permutation tests.
**Corresponding Notebook:** `21_test_hypothesis_H1.ipynb`

---

## 1. Objective

To perform a formal, rigorous statistical test of the primary landscape characterization hypothesis ($H_1$). This involves using both a parametric test (MANOVA) and a non-parametric test (a permutation test on persistence landscapes) to determine if the multiscale topological signatures of the two geomorphic provinces are statistically distinct.

## 2. Rationale and Strategic Justification

This protocol is the moment of truth for the first half of your entire project. It is the ultimate expression of **Structured Idealism**: the idealistic hypothesis that landscapes have unique, quantifiable "shapes" is now subjected to the cold, rigorous structure of formal statistical testing.

This is an act of **intellectual mastery**. The decision to use two different statistical methods is an "enthusiast-grade" choice that demonstrates a profound commitment to robust, defensible science. MANOVA is the classic, powerful tool for this question, while the permutation test provides a beautiful, assumption-free validation, ensuring your conclusions are not artifacts of a statistical model.

The **harmony and beauty** of this protocol are found in its logical purity. You will transform the complex, high-dimensional data and the compelling visualizations from the previous step into a single, decisive number: the p-value. This elegant reduction provides the **tangible service** of a clear, unambiguous, and scientifically credible answer to your first research question.

## 3. Implementation Protocol (Jupyter Notebook Workflow)

### Step 1: Data Preparation
* **Input:**
    * The training dataset with principal components (`data/processed/training_data_with_components.csv`).
    * The raw `final_training_dataset.csv` (for the permutation test).
* **Process:**
    1.  Load the dataset with components into a `pandas` DataFrame.
    2.  Isolate the variables for the MANOVA: the group identifier (`province_ID`) and the principal component scores (e.g., `PC1`, `PC2`, `PC3`, `PC4`) that explain ~95% of the variance.
    3.  For the permutation test, load the raw training data and isolate the group identifier and the full-dimensional TLSP vectors (e.g., all `tlsp_h1_pits_pl` values).

### Step 2: Parametric Test - Multivariate Analysis of Variance (MANOVA)
* **Input:** The prepared MANOVA data (group IDs and PCs).
* **Process:**
    1.  **Check Assumptions:** Briefly check the data for the key assumptions of MANOVA, such as homogeneity of covariance matrices (using Box's M test) and multivariate normality. Note any violations, which will reinforce the importance of the non-parametric test.
    2.  **Fit the Model:** Use the `statsmodels.multivariate.manova.MANOVA` class to fit the statistical model. The formula will be `from_formula('PC1 + PC2 + PC3 + PC4 ~ province_ID', data=df)`.
    3.  **Interpret the Results:** Print the MANOVA summary table. The key result is the p-value associated with the `province_ID` variable for a standard test statistic like Pillai's Trace or Wilks' Lambda.
    4.  **Conclusion:** If the p-value is less than your chosen alpha (e.g., 0.05), you have evidence to reject the null hypothesis.

### Step 3: Non-parametric Test - Permutation Test on Persistence Landscapes
This test provides a robust, assumption-free check on the MANOVA result.

* **Input:** The prepared permutation test data (group IDs and the most informative TLSP vectors, e.g., the Persistence Landscapes for $H_1$).
* **Process:**
    1.  **Define the Test Statistic:** The chosen statistic will be the **Euclidean distance between the centroids (mean vectors) of the two groups** in the high-dimensional TLSP feature space.
    2.  **Calculate the Observed Statistic:** Calculate this distance for your actual, un-shuffled data.
    3.  **Run the Permutation Loop:**
        * Initialize an empty list to store results.
        * Loop a large number of times (e.g., 9,999).
        * In each iteration, randomly shuffle the `province_ID` labels.
        * Recalculate the centroid distance for these newly formed random groups and append it to your results list.
    4.  **Calculate the p-value:** The p-value is the proportion of distances in your permuted results that are greater than or equal to your single *observed* distance. `p = (np.sum(permuted_distances >= observed_distance) + 1) / (n_permutations + 1)`.
    5.  **Visualize:** Create a histogram of the permuted distances and draw a vertical line showing where your observed distance falls.


### Step 4: Synthesize Results and Formally Conclude
* **Process:**
    1.  Display the results from both the MANOVA (p-value) and the permutation test (p-value and visualization) side-by-side.
    2.  Write a final, conclusive markdown cell in the notebook.
    3.  The conclusion should state clearly whether you **reject** or **fail to reject** the null hypothesis ($H_{01}$) and must reference the evidence from *both* statistical tests. For example: "The MANOVA test indicated a statistically significant difference between the geomorphic provinces (Pillai's Trace, p < .001). This result was confirmed by a non-parametric permutation test on the Persistence Landscape vectors, which also yielded a significant result (p = .002). Therefore, we reject the null hypothesis and conclude that the geomorphic provinces exhibit distinct multiscale topological signatures."

## 4. Deliverables

1.  **Jupyter Notebook (`21_test_hypothesis_H1.ipynb`)**: A fully executed notebook that serves as the complete statistical report for hypothesis $H_1$. It must contain:
    * The data preparation and assumption checks.
    * The results table from the MANOVA test.
    * The code, visualization, and final p-value from the permutation test.
    * A clear, final, written conclusion synthesizing the results and formally stating the outcome of the hypothesis test.

## 5. Quality Control Checklist

* [ ] The assumptions for MANOVA have been checked and documented.
* [ ] The results of both the MANOVA and the permutation test are reported.
* [ ] The number of permutations is sufficiently large (>= 999) for a stable p-value.
* [ ] The permutation test visualization (histogram) is clear and correctly interpreted.
* [ ] The final conclusion is unambiguous and supported by the statistical evidence from both tests.
* [ ] The entire analysis is reproducible via the Jupyter Notebook.