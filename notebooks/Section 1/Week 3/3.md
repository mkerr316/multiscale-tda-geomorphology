### **Document 2: Protocol 2.2 - Soils Data Processing**

```markdown
# Protocol 2.2: Processing Soils Data for WEPP

**Document Version:** 1.0
**Date:** September 27, 2025
**Associated Project Task:** 2.2 - Develop and execute scripts to process raw soil data into WEPP-required `.sol` files.
**Corresponding Notebook:** `05_process_soils_data.ipynb`

---

## 1. Objective

To process the raw Gridded Soil Survey Geographic (gSSURGO) database by linking the spatial map unit raster to the tabular soil property data. The final output is a set of formatted soil input files (`.sol`) required by the WEPP model, along with a raster map that links every pixel in the study area to its corresponding soil file.

## 2. Rationale and Strategic Justification

Soil properties are a primary control on the physical processes of infiltration and erosion that WEPP simulates. This task is a deep dive into geospatial data integration, requiring the methodical joining of complex relational database tables and linking them to a spatial layer. This process of creating a harmonized, analysis-ready soil dataset is a foundational act of "creative world-building" within the project's digital ecosystem. Successfully engineering this workflow provides a tangible service to the project by creating a beautiful and highly utilitarian data product that is essential for achieving a credible, high-impact scientific result.

## 3. Implementation Protocol (Jupyter Notebook Workflow)

### Step 1: Identify and Load gSSURGO Data
* **Input:** The downloaded gSSURGO database for the study region (`data/raw/soils/`) and the clipped map unit raster (`data/interim/soils_mapunit_clipped.tif`).
* **Process:**
    1.  Load the key tabular data files (typically `.txt` or `.csv` files within the gSSURGO package) into `pandas` DataFrames. The essential tables are:
        * `component`: Describes the soil components within each map unit.
        * `chorizon`: Contains the physical and chemical properties for each soil horizon.
        * `mapunit`: The master table linking the two.
    2.  Identify the unique map unit keys (`mukey`) present in the clipped map unit raster.

### Step 2: Perform Database Joins and Calculate Weighted Averages
This is the most complex step in the protocol. The goal is to derive a single, representative soil profile for each map unit (`mukey`).

* **Process:**
    1.  **Filter:** Reduce the enormous national tables to only include the `mukey` values present in your study areas.
    2.  **Join:** Perform a series of `pandas` merges:
        * Merge `mapunit` with `component` on `mukey`.
    3.  **Select Dominant Component:** For each `mukey`, identify the dominant soil component based on the `comppct_r` (representative component percentage) field.
    4.  **Join with Horizon Data:** Merge the result with the `chorizon` table on `cokey` (component key) to get the properties for all horizons of the dominant component.
    5.  **Calculate WEPP Parameters:** From the final joined table, extract or calculate the soil properties required by WEPP for each horizon. These include:
        * Sand, silt, and clay percentage (`sandtotal_r`, `silttotal_r`, `claytotal_r`).
        * Organic matter (`om_r`).
        * Cation-exchange capacity (`cec7_r`).
        * Rock fragment content (`fragvol_r`).

### Step 3: Generation of WEPP Soil Files (`.sol`)
* **Input:** The final, processed DataFrame containing soil properties for each dominant component.
* **Process:**
    1.  Write a Python function that takes a `cokey` (or `mukey`) as input.
    2.  The function will query the DataFrame for that component's horizon data.
    3.  It will then write a new, correctly formatted `.sol` file. This is a highly structured text file that describes the properties of each soil layer. The function must follow the WEPP `.sol` format specifications precisely.
    4.  Iterate through all unique dominant components in the study area and generate a `.sol` file for each one.


### Step 4: Create the Final Soils Raster Map
* **Process:**
    1.  Create a raster map where each pixel's value is the numeric ID of the dominant soil component (`cokey`) for that location. This involves a raster reclassification based on the `mukey` -> dominant `cokey` relationship established in Step 2.
    2.  This final raster serves as the master "lookup" grid. During WEPP execution, the model will query a pixel's value on this map to know which `.sol` file to use for the simulation.

## 4. Deliverables

1.  **WEPP Soil Files (`.sol`):** A directory (`data/processed/soils/sol_files/`) containing all generated `.sol` files, named by their corresponding `cokey`.
2.  **Final Soils Map:** A GeoTIFF raster (`data/processed/soils/dominant_soil_map.tif`) where pixel values correspond to the `cokey` of the dominant soil component.
3.  **Jupyter Notebook (`05_process_soils_data.ipynb`)**: A fully executed notebook documenting the entire workflow, including the gSSURGO table joins, parameter calculations, and `.sol` file generation logic.

## 5. Quality Control Checklist

* [ ] Database joins are validated to ensure data integrity.
* [ ] A clear and defensible method for selecting the dominant soil component is documented.
* [ ] Calculated soil parameters are within physically plausible ranges (e.g., sand+silt+clay â‰ˆ 100%).
* [ ] Generated `.sol` files are correctly formatted and pass WEPP validation checks.
* [ ] The final soils map correctly links every pixel to a generated `.sol` file.