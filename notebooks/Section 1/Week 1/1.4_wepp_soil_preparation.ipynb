{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''#%% md\n",
    "# 1.4: WEPP Soil (.sol) File Preparation\n",
    "\n",
    "**Objective:** To process the raw tabular gNATSGO soil data (component and horizon information) and generate a WEPP-compatible soil file (`.sol`) for each study area. This is a complex data engineering task that involves creating a single representative soil profile from multiple soil components within an area.\n",
    "\n",
    "**Gold-Standard Practices Implemented:**\n",
    "- **Configuration-Driven:** All paths and parameters are loaded from the central `config.yml`.\n",
    "- **Representative Profile Generation:** Outlines the methodology for creating a single, representative soil profile for an analysis area by analyzing dominant components and their horizons.\n",
    "- **Pedotransfer Function (PTF) Placeholders:** Explicitly notes where PTFs are needed to estimate WEPP-specific parameters (like erodibility) from basic soil properties (like texture).\n",
    "- **Custom Formatting:** A dedicated function will format the final representative profile into the precise, structured ASCII format required by the WEPP model.\n"
   ],
   "id": "3d707755f03886ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === 1. Configuration & Setup ===\n",
    "\n",
    "# --- Core Libraries ---\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Project-Specific Modules ---\n",
    "# Add project's src directory to path to allow imports\n",
    "def find_project_root(marker='config.yml'):\n",
    "    path = Path.cwd().resolve()\n",
    "    while path.parent != path:\n",
    "        if (path / marker).exists(): return path\n",
    "        path = path.parent\n",
    "    raise FileNotFoundError(f\"Project root with marker '{marker}' not found.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
    "\n",
    "from utils import setup_colored_logging\n",
    "\n",
    "# --- Geospatial & Data Libraries ---\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Gold-Standard Logging Setup ---\n",
    "setup_colored_logging()\n",
    "log = logging.getLogger(\"1.4_wepp_soil_preparation\")\n",
    "\n",
    "# --- Configuration Loading ---\n",
    "CONFIG_PATH = PROJECT_ROOT / \"config.yml\"\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# --- Path Configuration (from config) ---\n",
    "STUDY_AREAS_GPKG = PROJECT_ROOT / config['paths']['study_areas']\n",
    "RAW_SOILS_DIR = PROJECT_ROOT / config['paths']['soils_dir']\n",
    "PROCESSED_SOILS_DIR = PROJECT_ROOT / config['paths']['processed_dir'] / 'soils_sol'\n",
    "GNATSGO_JOB_NAME = config['data_sources']['gnatsgo']['job_name']\n",
    "\n",
    "# The primary input file from notebook 1.2\n",
    "TABULAR_SOIL_DATA_CSV = RAW_SOILS_DIR / f\"{GNATSGO_JOB_NAME}_tabular_data.csv\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "PROCESSED_SOILS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "log.info(\"--- Configuration Summary ---\")\n",
    "log.info(f\"Project Root:          {PROJECT_ROOT}\")\n",
    "log.info(f\"Input Study Areas:     {STUDY_AREAS_GPKG}\")\n",
    "log.info(f\"Input Tabular Soils:   {TABULAR_SOIL_DATA_CSV}\")\n",
    "log.info(f\"Output .sol Files:     {PROCESSED_SOILS_DIR}\")\n",
    "log.info(\"Setup complete.\")\n"
   ],
   "id": "32cfaaad59d0f4aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === 2. Load Input Data ===\n",
    "\n",
    "def load_input_data(gpkg_path: Path, csv_path: Path) -> tuple[gpd.GeoDataFrame, pd.DataFrame]:\n",
    "    \"\"\"Loads the study area polygons and the tabular soil data.\"\"\"\n",
    "    log.info(f\"Loading study area polygons from {gpkg_path}\")\n",
    "    if not gpkg_path.exists():\n",
    "        raise FileNotFoundError(f\"Study areas file not found. Please run notebook 1.1.\")\n",
    "    study_areas = gpd.read_file(gpkg_path, layer='cv_provinces')\n",
    "    log.info(f\"Loaded {len(study_areas)} study area polygons.\")\n",
    "\n",
    "    log.info(f\"Loading tabular soil data from {csv_path}\")\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Tabular soil data not found. Please run notebook 1.2.\")\n",
    "    soil_data = pd.read_csv(csv_path)\n",
    "    log.info(f\"Loaded {len(soil_data)} soil horizon records.\")\n",
    "    \n",
    "    return study_areas, soil_data\n",
    "\n",
    "# --- Execute ---\n",
    "study_areas_gdf, soil_data_df = load_input_data(STUDY_AREAS_GPKG, TABULAR_SOIL_DATA_CSV)\n",
    "display(study_areas_gdf.head())\n",
    "display(soil_data_df.head())\n"
   ],
   "id": "54c2cd3e814a8fdc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Soil Profile Generation Strategy\n",
    "\n",
    "The core challenge in creating a `.sol` file is converting the complex, multi-component gNATSGO data into a single, representative soil profile for each analysis area. WEPP models a single hillslope with one set of soil parameters, so an aggregation is required.\n",
    "\n",
    "Our strategy will be:\n",
    "\n",
    "1.  **Identify the Dominant Soil Component:** For each study area polygon, we must first determine which soil map units fall within it. The tabular data we fetched already links map unit keys (`mukey`) to soil components (`cokey`). The most straightforward approach is to select the single most dominant component (by `comppct_r`) within the area of interest. A more advanced method would involve area-weighting the properties of several top components.\n",
    "\n",
    "2.  **Extract the Horizon Profile:** Once the dominant component (`cokey`) is identified, we extract all of its associated horizons (`chkey`) from the tabular data, ordered by depth.\n",
    "\n",
    "3.  **Estimate WEPP Parameters (PTFs):** The WEPP model requires specific erosion and hydraulic parameters that are not directly provided in gNATSGO. These must be estimated from basic soil properties using **Pedotransfer Functions (PTFs)**. Key parameters to estimate include:\n",
    "    *   **`Ki` (Interrill Erodibility)**\n",
    "    *   **`Kr` (Rill Erodibility)**\n",
    "    *   **`shcrit` (Critical Shear Stress)**\n",
    "    *   **`Ksat` (Saturated Hydraulic Conductivity)**\n",
    "    This notebook will put placeholders for these values, but a full scientific implementation requires researching and applying appropriate PTFs (e.g., from the WEPP technical documentation or literature).\n",
    "\n",
    "4.  **Format and Write the `.sol` File:** A dedicated function will take the final, processed profile for a study area and write it to the strict ASCII format that WEPP requires.\n"
   ],
   "id": "1f5554afee607e9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === 3. Core Soil Processing Logic ===\n",
    "\n",
    "# This is a placeholder for the core data processing logic.\n",
    "# A full implementation would involve:\n",
    "# 1. Iterating through each polygon in `study_areas_gdf`.\n",
    "# 2. Spatially intersecting the polygon with soil map unit geometry (requires more data from SDA or a GIS layer).\n",
    "# 3. Based on the intersection, identifying the dominant component `cokey` from `soil_data_df`.\n",
    "# 4. Filtering `soil_data_df` to get all horizons for that dominant `cokey`.\n",
    "# 5. Creating a new DataFrame representing the single, representative profile.\n",
    "# 6. Applying PTFs to estimate erodibility and conductivity parameters.\n",
    "# 7. Passing the final profile DataFrame to the formatting function below.\n",
    "\n",
    "log.warning(\"Placeholder cell: Core data processing logic needs to be implemented.\")\n",
    "\n",
    "# Example structure:\n",
    "# for index, area in study_areas_gdf.iterrows():\n",
    "#     area_id = area['some_unique_id']\n",
    "#     log.info(f\"Processing soil profile for {area_id}...\")\n",
    "#     \n",
    "#     # Check if final .sol file already exists\n",
    "#     sol_output_path = PROCESSED_SOILS_DIR / f\"{area_id}.sol\"\n",
    "#     if sol_output_path.exists():\n",
    "#         log.info(f\"  -> Skipping, {sol_output_path.name} already exists.\")\n",
    "#         continue\n",
    "#\n",
    "#     # ... implementation of steps 1-6 ...\n",
    "#     representative_profile_df = ...\n",
    "#\n",
    "#     # ... call formatter ...\n",
    "#     write_wepp_sol_file(representative_profile_df, sol_output_path)\n",
    "\n"
   ],
   "id": "db38fdbb13324c4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === 4. WEPP .sol Formatter ===\n",
    "\n",
    "def write_wepp_sol_file(profile_df: pd.DataFrame, out_path: Path):\n",
    "    \"\"\"\n",
    "    Formats a DataFrame of a representative soil profile into a WEPP .sol file.\n",
    "\n",
    "    Args:\n",
    "        profile_df (pd.DataFrame): Must contain horizon data with columns like \n",
    "                                   'hzdept_r', 'hzdepb_r', 'sandtotal_r', 'claytotal_r', \n",
    "                                   'om_r', 'cec7_r', 'fragvol_r'.\n",
    "        out_path (Path): The full path for the output .sol file.\n",
    "    \"\"\"\n",
    "    log.info(f\"Generating WEPP .sol file: {out_path.name}\")\n",
    "\n",
    "    num_horizons = len(profile_df)\n",
    "    if num_horizons == 0:\n",
    "        log.warning(f\"Cannot write {out_path.name}, profile data is empty.\")\n",
    "        return\n",
    "\n",
    "    # --- Placeholder for PTF-derived parameters ---\n",
    "    # These values should be calculated based on soil properties.\n",
    "    Ki_placeholder = 300000  # Interrill erodibility\n",
    "    Kr_placeholder = 0.000003 # Rill erodibility\n",
    "    shcrit_placeholder = 3.0   # Critical shear\n",
    "    Ksat_placeholder = 5.0     # Saturated hydraulic conductivity (mm/hr)\n",
    "\n",
    "    with open(out_path, 'w') as f:\n",
    "        # --- Write Header ---\n",
    "        f.write(\"98.4\\n\") # WEPP version\n",
    "        f.write(\"#\\n\")\n",
    "        f.write(f\"# Soil file generated by notebook 1.4 on {pd.Timestamp.now().strftime('%Y-%m-%d')}\\n\")\n",
    "        f.write(f\"# Profile based on dominant component from gNATSGO.\\n\")\n",
    "        f.write(\"# Erodibility and conductivity are PLACEHOLDERS and require PTFs.\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(f\"{num_horizons} # Number of horizons\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # --- Write Horizon Data ---\n",
    "        for i, row in enumerate(profile_df.itertuples()):\n",
    "            # Calculate horizon thickness in meters\n",
    "            thickness_m = (row.hzdepb_r - row.hzdept_r) / 100.0\n",
    "            \n",
    "            f.write(f\"'Horizon {i+1}'\\n\")\n",
    "            f.write(f\"{thickness_m:.3f} {row.sandtotal_r:.1f} {row.claytotal_r:.1f} {row.om_r:.2f} {row.cec7_r:.2f} {row.fragvol_r:.1f}\\n\")\n",
    "            f.write(f\"{Ki_placeholder} {Kr_placeholder} {shcrit_placeholder} {Ksat_placeholder}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    log.info(f\"✅ Successfully wrote {out_path.name}\")\n",
    "\n",
    "log.warning(\"Placeholder cell: Formatting function is defined but not yet called.\")\n",
    "\n",
    "'''"
   ],
   "id": "34c6d0fed840043e"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
