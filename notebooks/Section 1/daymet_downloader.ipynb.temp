{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825821bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8. Acquire Daymet Daily Climate Data ===\n",
    "\n",
    "DAYMET_COLLECTION = \"daymet-daily-na\"\n",
    "DAYMET_ZARR_ROLES = (\"zarr\",)\n",
    "DAYMET_VARIABLE_MAP = {\n",
    "    \"ppt\": \"prcp\",\n",
    "    \"prcp\": \"prcp\",\n",
    "    \"tmin\": \"tmin\",\n",
    "    \"tmax\": \"tmax\",\n",
    "}\n",
    "\n",
    "def _aoi_bounds_4326(aoi_gdf: gpd.GeoDataFrame) -> tuple[float, float, float, float]:\n",
    "    aoi_4326 = aoi_gdf.to_crs(WGS84_CRS)\n",
    "    minx, miny, maxx, maxy = aoi_4326.total_bounds\n",
    "    return float(minx), float(miny), float(maxx), float(maxy)\n",
    "\n",
    "def _to_time_slice(start_str: str, end_str: str) -> slice:\n",
    "    return slice(pd.to_datetime(start_str), pd.to_datetime(end_str))\n",
    "\n",
    "def _coord_names(ds: xr.Dataset) -> tuple[str, str]:\n",
    "    lat = \"lat\" if \"lat\" in ds.coords else (\"y\" if \"y\" in ds.coords else None)\n",
    "    lon = \"lon\" if \"lon\" in ds.coords else (\"x\" if \"x\" in ds.coords else None)\n",
    "    if not lat or not lon:\n",
    "        raise ValueError(f\"Could not locate latitude/longitude coordinates in Daymet dataset. Found: {list(ds.coords)}\")\n",
    "    return lat, lon\n",
    "\n",
    "def _resolve_daymet_asset_href(collection) -> str | None:\n",
    "    asset = collection.assets.get(\"zarr\")\n",
    "    if asset is not None:\n",
    "        return asset.href\n",
    "    for asset in collection.assets.values():\n",
    "        roles = tuple(asset.roles or ())\n",
    "        if asset.href.endswith(\".zarr\") or any(role in DAYMET_ZARR_ROLES for role in roles):\n",
    "            return asset.href\n",
    "    return None\n",
    "\n",
    "def _normalize_daymet_variables(requested: Sequence[str]) -> dict[str, str]:\n",
    "    normalized: dict[str, str] = {}\n",
    "    for var in requested:\n",
    "        dataset_var = DAYMET_VARIABLE_MAP.get(var)\n",
    "        if dataset_var is None:\n",
    "            log.warning(f\"Requested climate variable '{var}' is not available in the Daymet collection and will be skipped.\")\n",
    "            continue\n",
    "        normalized[var] = dataset_var\n",
    "    return normalized\n",
    "\n",
    "def acquire_daymet_daily_via_zarr(\n",
    "    aoi_gdf: gpd.GeoDataFrame,\n",
    "    variables: Sequence[str] | None = None,\n",
    "    clip_polygon: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"Download daily Daymet climate data from the Planetary Computer Zarr cube.\"\"\"\n",
    "    requested = tuple(variables) if variables is not None else tuple(PRISM_DAILY_VARS)\n",
    "    var_map = _normalize_daymet_variables(requested)\n",
    "    if not var_map:\n",
    "        log.error(\"No valid climate variables were requested. Aborting Daymet acquisition.\")\n",
    "        return\n",
    "\n",
    "    log.info(\"--- Starting Daymet daily climate acquisition via Planetary Computer ---\")\n",
    "    log.info(f\"Variables requested: {list(var_map.keys())}\")\n",
    "\n",
    "    catalog = Client.open(PC_STAC_URL)\n",
    "    collection = catalog.get_collection(DAYMET_COLLECTION)\n",
    "    if collection is None:\n",
    "        log.error(f\"Unable to locate collection '{DAYMET_COLLECTION}' on the Planetary Computer.\")\n",
    "        return\n",
    "\n",
    "    asset_href = _resolve_daymet_asset_href(collection)\n",
    "    if asset_href is None:\n",
    "        log.error(\"No Zarr asset was found for the Daymet collection; cannot proceed with climate acquisition.\")\n",
    "        return\n",
    "\n",
    "    signed_href = planetary_computer.sign(asset_href)\n",
    "    mapper = fsspec.get_mapper(signed_href, anon=True)\n",
    "\n",
    "    try:\n",
    "        ds = xr.open_zarr(mapper, consolidated=True)\n",
    "    except TypeError:\n",
    "        ds = xr.open_zarr(mapper)\n",
    "\n",
    "    lat_name, lon_name = _coord_names(ds)\n",
    "\n",
    "    time_slice = _to_time_slice(PRISM_DATE_RANGE[0], PRISM_DATE_RANGE[1])\n",
    "    ds_time = ds.sel(time=time_slice)\n",
    "\n",
    "    minx, miny, maxx, maxy = _aoi_bounds_4326(aoi_gdf)\n",
    "    spatial_subset = ds_time.sel({\n",
    "        lon_name: slice(minx, maxx),\n",
    "        lat_name: slice(maxy, miny),\n",
    "    })\n",
    "\n",
    "    if spatial_subset.time.size == 0:\n",
    "        log.error(\"No temporal data remained after subsetting the Daymet cube. Please check the configured date range.\")\n",
    "        return\n",
    "\n",
    "    clip_geom = None\n",
    "    if clip_polygon:\n",
    "        clip_geom = [mapping(aoi_gdf.to_crs(WGS84_CRS).unary_union)]\n",
    "\n",
    "    out_root = CLIMATE_OUT_DIR / \"daily\"\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    start_year = pd.to_datetime(PRISM_DATE_RANGE[0]).year\n",
    "    end_year = pd.to_datetime(PRISM_DATE_RANGE[1]).year\n",
    "\n",
    "    total_saved = 0\n",
    "    for output_var, dataset_var in var_map.items():\n",
    "        if dataset_var not in spatial_subset.data_vars:\n",
    "            log.warning(f\"Daymet dataset does not include variable '{dataset_var}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        da = spatial_subset[dataset_var]\n",
    "        if clip_geom is not None:\n",
    "            da = da.rio.write_crs(\"EPSG:4326\")\n",
    "            da = da.rio.clip(clip_geom, \"EPSG:4326\", drop=True)\n",
    "        da = da.rename(output_var)\n",
    "\n",
    "        var_dir = out_root / output_var\n",
    "        var_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            year_slice = slice(f\"{year}-01-01\", f\"{year}-12-31\")\n",
    "            da_year = da.sel(time=year_slice)\n",
    "            if da_year.sizes.get(\"time\", 0) == 0:\n",
    "                continue\n",
    "\n",
    "            out_path = var_dir / f\"daymet_{output_var}_daily_{year}.nc\"\n",
    "            if out_path.exists():\n",
    "                log.info(f\"Skipping existing Daymet file: {out_path.name}\")\n",
    "                continue\n",
    "\n",
    "            tmp_path = out_path.with_suffix(out_path.suffix + \".part\")\n",
    "            da_year.to_netcdf(tmp_path)\n",
    "            tmp_path.replace(out_path)\n",
    "\n",
    "            write_provenance(\n",
    "                artifact_path=out_path,\n",
    "                source_info={\n",
    "                    \"stac_collection\": DAYMET_COLLECTION,\n",
    "                    \"asset_href\": asset_href,\n",
    "                    \"platform\": \"Microsoft Planetary Computer\",\n",
    "                },\n",
    "                parameters={\n",
    "                    \"requested_variable\": output_var,\n",
    "                    \"dataset_variable\": dataset_var,\n",
    "                    \"time_range\": [f\"{year}-01-01\", f\"{year}-12-31\"],\n",
    "                    \"spatial_subset\": \"polygon\" if clip_polygon else \"bbox\",\n",
    "                },\n",
    "            )\n",
    "            total_saved += 1\n",
    "\n",
    "    log.info(f\"âœ… Daymet export complete. Saved {total_saved} new file(s) under {out_root}.\")\n",
    "    log.info(\"Daymet precipitation units are millimeters/day; temperatures are in degrees Celsius.\")\n",
    "\n",
    "# Run it\n",
    "acquire_daymet_daily_via_zarr(master_aoi_wgs84, variables=PRISM_DAILY_VARS, clip_polygon=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
