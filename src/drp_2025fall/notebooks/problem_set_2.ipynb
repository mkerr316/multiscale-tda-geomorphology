{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\n\n# Add the root directory to sys.path so that 'src' can be imported\nnotebook_dir = os.getcwd()\nroot_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\nif root_dir not in sys.path:\n\tsys.path.insert(0, root_dir)\n\nfrom src.drp_fall_2025.topology import SimplicialComplex\nfrom src.drp_fall_2025.analysis import compute_betti_numbers, compute_euler_characteristic, plot_betti_distributions\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom tqdm import trange\n\n# Set style for better-looking plots\nsns.set_theme(style=\"whitegrid\", palette=\"colorblind\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2: Simplicial Homology\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates:\n",
    "1. Creating random simplicial complexes\n",
    "2. Computing Euler characteristics\n",
    "3. Computing Betti numbers over Z/2Z\n",
    "4. Statistical analysis of topological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a simple simplicial complex\n",
    "\n",
    "# Define a triangle with its edges and vertices\n",
    "# Vertices: 0, 1, 2\n",
    "# Edges: (0,1), (1,2), (0,2)\n",
    "# Triangle: (0,1,2)\n",
    "\n",
    "triangle_complex = SimplicialComplex.from_maximal_simplices([\n",
    "    [0, 1, 2]  # This will automatically generate all faces\n",
    "])\n",
    "\n",
    "print(f\"Complex: {triangle_complex}\")\n",
    "print(f\"All simplices: {sorted(triangle_complex.simplices)}\")\n",
    "print(f\"Euler characteristic: {compute_euler_characteristic(triangle_complex)}\")\n",
    "print(f\"Betti numbers: {compute_betti_numbers(triangle_complex)}\")\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "print(\"\\tβ₀ = 1: One connected component\")\n",
    "print(\"\\tβ₁ = 0: No holes (the triangle is filled in)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Random Complex Generation and Betti Number Analysis\n",
    "\n",
    "**Task**: Generate 100 random complexes from 10 vertices and analyze their Betti numbers.\n",
    "\n",
    "We use a bottom-up probabilistic model where simplices at each dimension are added\n",
    "with probability 0.5, provided their boundary faces are already present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration constants\n",
    "NUM_VERTICES = 10\n",
    "NUM_RUNS = 100\n",
    "PROBABILITY = 0.5\n",
    "MAX_DIMENSION = 10\n",
    "\n",
    "# Uniform probabilities using dict comprehension\n",
    "P_DICT = {i: PROBABILITY for i in range(1, MAX_DIMENSION + 1)}\n",
    "\n",
    "print(f\"We will run this simulation with {NUM_RUNS} runs on {NUM_VERTICES} vertices.\")\n",
    "print(f\"Probabilities: p_k = {PROBABILITY} for all dimensions k ∈ [1, {MAX_DIMENSION}]\")\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random complexes with progress bar\n",
    "for i in trange(NUM_RUNS, desc=\"Generating complexes\"):\n",
    "    complex_k = SimplicialComplex.from_bottom_up_process(NUM_VERTICES, P_DICT)\n",
    "    betti = compute_betti_numbers(complex_k)\n",
    "    results.append(betti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Constants for formatting\nSEPARATOR = \"=\" * 60\n\n# Chain pandas operations for efficiency\ndf = pd.DataFrame(results).fillna(0).astype(int)\n\n# Compute statistics once\ndf_mean = df.mean()\ndf_std = df.std()\ndf_median = df.median()\n\nprint(\"\\n\" + SEPARATOR)\nprint(\"STATISTICAL SUMMARY\")\nprint(SEPARATOR)\n\nprint(\"\\n--- Average Betti Numbers ---\")\nprint(df_mean.to_string())\n\nprint(\"\\n--- Full Statistical Summary ---\")\nprint(df.describe().to_string())\n\nprint(\"\\n--- Additional Statistics ---\")\nprint(f\"Standard Deviations: {df_std.to_dict()}\")\nprint(f\"Medians: {df_median.to_dict()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n--- Automated Insights ---\")\n\nfor col in sorted(df.columns):\n    # Reuse precomputed statistics\n    mean_val = df_mean[col]\n    std_val = df_std[col]\n    median_val = df_median[col]\n    nonzero_pct = (df[col] > 0).sum() / len(df) * 100\n    max_val = df[col].max()\n    \n    print(f\"\\nβ_{col}:\")\n    print(f\"  • Mean: {mean_val:.2f}, Median: {median_val:.1f}, Std Dev: {std_val:.2f}\")\n    print(f\"  • Range: [0, {max_val}]\")\n    print(f\"  • Non-zero in {nonzero_pct:.1f}% of complexes\")\n    \n    # Dimension-specific interpretation\n    if col == 0:\n        if mean_val > 1.5:\n            print(f\"  • Complexes are frequently disconnected (avg {mean_val:.2f} components)\")\n        elif mean_val < 1.2:\n            print(f\"  • Complexes are usually connected\")\n        else:\n            print(f\"  • Complexes sometimes fragment into multiple components\")\n    elif col == 1:\n        if mean_val > 5:\n            print(f\"  • Many loops form (p={PROBABILITY} creates rich 1-dimensional structure)\")\n        else:\n            print(f\"  • Few loops form\")\n    elif col == 2:\n        if mean_val > 0.5:\n            print(f\"  • Voids form occasionally (higher-dimensional structure)\")\n        else:\n            print(f\"  • Voids are rare (as expected with random generation)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Constants for correlation analysis\nMODERATE_THRESHOLD = 0.3\nSTRONG_THRESHOLD = 0.7\n\nif len(df.columns) > 1:\n    print(\"\\n\" + SEPARATOR)\n    print(\"CORRELATION ANALYSIS\")\n    print(SEPARATOR)\n    \n    correlation_matrix = df.corr()\n    print(\"\\nCorrelation Matrix:\")\n    print(correlation_matrix.to_string())\n\n    print(\"\\n--- Key Correlations ---\")\n    \n    # Use the upper triangle of the matrix to avoid duplicates and self-correlation\n    upper_triangle = correlation_matrix.where(\n        np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n    )\n    \n    # Unstack to a Series and drop missing values\n    strong_corrs = upper_triangle.stack()\n    \n    # Filter for meaningful correlations\n    significant_corrs = strong_corrs[abs(strong_corrs) >= MODERATE_THRESHOLD]\n\n    if significant_corrs.empty:\n        print(f\"No significant correlations (|r| ≥ {MODERATE_THRESHOLD}) found.\")\n    else:\n        for (col1, col2), corr_val in significant_corrs.items():\n            direction = \"positive\" if corr_val > 0 else \"negative\"\n            strength = \"strong\" if abs(corr_val) > STRONG_THRESHOLD else \"moderate\"\n            print(f\"{col1} and {col2}: {strength} {direction} correlation ({corr_val:.3f})\")\n\n    # Correlation Heatmap\n    fig, ax = plt.subplots(figsize=(8, 6))\n    sns.heatmap(\n        correlation_matrix, \n        annot=True, \n        cmap='coolwarm', \n        center=0, \n        ax=ax,\n        fmt='.3f',\n        square=True,\n        cbar_kws={'label': 'Pearson Correlation Coefficient'},\n        linewidths=0.5,\n        linecolor='white',\n        vmin=-1,\n        vmax=1\n    )\n    ax.set_title('Correlation between Betti Numbers', fontsize=15, fontweight='bold', pad=20)\n    \n    # Improve tick label presentation\n    plt.xticks(rotation=45, ha='right', rotation_mode='anchor')\n    plt.yticks(rotation=0)\n    \n    ax.tick_params(left=False, bottom=False) # Removes tick marks for a cleaner look\n    \n    plt.tight_layout(pad=1.5)\n    plt.show()\n\nelse:\n    print(\"\\n(Only one Betti number column present - skipping correlation analysis)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme Cases Analysis\n",
    "print(\"\\n\" + SEPARATOR)\n",
    "print(\"EXTREME CASES\")\n",
    "print(SEPARATOR)\n",
    "\n",
    "for col in sorted(df.columns):\n",
    "    if df[col].max() > 0:\n",
    "        max_idx = df[col].idxmax()\n",
    "        min_idx = df[col].idxmin()\n",
    "        \n",
    "        print(f\"\\nβ_{col}:\")\n",
    "        print(f\"  • Maximum: {df.loc[max_idx, col]} (in run #{max_idx})\")\n",
    "        other_cols = [c for c in df.columns if c != col]\n",
    "        if other_cols:\n",
    "            other_bettis = {f\"β_{c}\": df.loc[max_idx, c] for c in df.columns if c != col}\n",
    "            print(f\"    Other Betti numbers: {other_bettis}\")\n",
    "        \n",
    "        print(f\"  • Minimum: {df.loc[min_idx, col]} (in run #{min_idx})\")\n",
    "        if other_cols:\n",
    "            other_bettis = {f\"β_{c}\": df.loc[min_idx, c] for c in df.columns if c != col}\n",
    "            print(f\"    Other Betti numbers: {other_bettis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate the plots using the outsourced function\nplot_betti_distributions(df, NUM_RUNS)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}