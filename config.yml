paths:
  # --- Foundational Data ---
  data_dir: "data"
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  outputs_dir: "outputs"

  # --- Key Inputs ---
  provinces_input: "data/raw/boundaries/study_provinces.shp"

  # --- Key Intermediate Products (Inputs for downstream tasks) ---
  study_areas: "data/processed/study_areas.gpkg"
  external_holdout: "data/processed/external_holdout.gpkg"
  master_aoi: "data/processed/master_aoi.gpkg"

  # --- Raw Data Storage (Products of data acquisition) ---
  dem_dir: "data/raw/dem_30m"
  climate_dir: "data/raw/climate_daymet"
  soils_dir: "data/raw/soils_gnatsgo"

  # --- Processed Data Products (Derived from raw data) ---
  climate_cli_dir: "data/processed/climate_cli"
  soils_sol_dir: "data/processed/soils_sol"
  dem_clipped_dir: "data/processed/dem_aoi_clipped"
  covariates_dir: "data/processed/covariates"

  # --- Output Directories (Reports, figures, diagnostics) ---
  reports_data_acquisition: "outputs/data_acquisition"
  diagnostic_probes_dir: "outputs/data_acquisition/diagnostic_probes"
  maps_dir: "outputs/maps"

data_sources:
  dem:
    stac_url: "https://planetarycomputer.microsoft.com/api/stac/v1"
    collection: "3dep-seamless"
    asset_key: "data"
    # Ground sampling distance (resolution) in meters
    # 10 = 10m resolution (higher detail, slower downloads, more disk space)
    # 30 = 30m resolution (faster downloads, less disk space, RECOMMENDED for development)
    gsd: 30
  daymet:
    collection: "daymet-daily-na"
    # Download ALL Daymet V4 variables for robustness and future-proofing
    # Daymet provides 7 variables: prcp, tmin, tmax, srad, vp, dayl, swe
    # WEPP requires: prcp, tmin, tmax, srad (+ vp for dewpoint calculation)
    # Downloading all variables adds minimal overhead (7 vs 4 = ~75% more data)
    # but ensures completeness for any future climate analysis needs
    daily_variables: null  # null = download all available variables
    date_range: [ "2018-01-01", "2022-12-31" ]
  gnatsgo:
    raster_collection: "gnatsgo-rasters"
    table_collection: "gnatsgo-tables"
    # --- Gold-Standard: Specify Item IDs and Asset Keys separately ---
    # Asset key within the raster item
    raster_asset_key: "mukey"
    # Item IDs for the specific tables within the table_collection
    component_item_id: "comp"
    horizon_item_id: "chorizon"
    # The asset key for the Parquet file within each tabular item
    table_item_asset_key: "data"
    # Output filenames
    raster_filename: "gnatsgo_mukey.tif"
    component_filename: "gnatsgo_component.parquet"
    horizon_filename: "gnatsgo_horizon.parquet"
parameters:
  # CRS for data discovery and web services (WGS84)
  wgs84_crs: "EPSG:4326"
  # CRS for geometric operations and analysis (projected)
  processing_crs: "EPSG:5070"
  # Parameters for geometric processing
  border_gap_m: 0
  overlap_area_tol_m2: 1.0
  precision_grid_size: 1.0
  cv_province_id_col: "PROVINCE"
  external_holdout_id_col: "PROVINCE"

study_area_selection:
  cv_provinces:
    - "VALLEY AND RIDGE"
    - "PIEDMONT"
    - "COASTAL PLAIN"
    - "APPALACHIAN PLATEAUS"
    - "BLUE RIDGE"
  external_holdout_province: "BASIN AND RANGE"

# ----------------------------------------------------
# WEPPcloud Target Variable Generation
# ----------------------------------------------------
weppcloud:
  # Path to the Area of Interest (AOI) shapefile that defines the simulation boundary.
  aoi_path: "data/raw/boundaries/study_provinces.shp"

  # Number of years for the climate simulation. 100 years is the standard for
  # generating a stable, long-term average annual sediment yield.
  simulation_years: 100

  # Directory where the final target raster will be saved.
  output_directory: "data/processed/target_variable/"

  # A descriptive name for the project run on the WEPPcloud server.
  project_name: "Multiscale_TDA_Geomorphology_Fall2025"

# ----------------------------------------------------
# Computational Resources & GPU Configuration
# ----------------------------------------------------
computational:
  # GPU usage policy:
  #   - "auto": Use GPU if available, fallback to CPU if not (RECOMMENDED)
  #   - "force": Require GPU, fail if not available
  #   - "never": Always use CPU even if GPU is available
  use_gpu: "auto"

  # Fraction of GPU VRAM to reserve for computations (0.0-1.0)
  # 0.8 = 80% of VRAM, leaving 20% buffer for OS/other processes
  gpu_memory_fraction: 0.8

  # If true, fall back to CPU if GPU runs out of memory
  # If false, raise error on GPU OOM
  fallback_to_cpu_on_oom: true

  # Dask worker configuration (applies to both CPU and GPU workers)
  dask:
    # Number of worker processes
    # "auto" = number of physical CPU cores
    # Can override with integer (e.g., 8 for 8 workers)
    n_workers: "auto"

    # Threads per worker
    # 1 is recommended to avoid nested parallelism issues
    threads_per_worker: 1

    # Memory limit per worker
    # "auto" = (80% of available RAM) / n_workers
    # Can override with string (e.g., "4GB" for 4 GB per worker)
    memory_limit: "auto"

    # Dashboard port for monitoring (http://localhost:8787)
    dashboard_port: 8787